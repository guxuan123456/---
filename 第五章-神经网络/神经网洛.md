# 神经网络

上一章介绍了决策树，首先整了决策树的基本概念。构造决策树的递归流程和递归终止条件。决策树算法中主要是属性划分，根据属性划分的不同讨论了三种估计属性划分结果的经典算法，介绍通过剪枝策略来解决决策树的过拟合问题。最后分析了属性连续值、缺失值处理方法。这次我们要来点厉害的东西，比树更牛逼的一个东西-神经网络。

线性模型虽然简单，但是不易处理复杂的数据分布，图像识别作为一个分类问题，即识别图像中目标的类别，需要判定的东西很多，而且我们知道照片实际上是一个个像素点组成的，所以当采用回归方式处理时计算量很大，而人工神经网络是另一种常用的图像处理技术。


神经网络学习主要特点如下：
- 非线性映射逼近能力。可以逼近任意的连续非线性函数映射关系。
- 自适应性和自组织性。神经元之间的连接具有多样性，各神经元之间的连接强度具有可塑性，网络可以通过学习与训练进行自组织。
- 分布存储和容错性。网络的每部分对信息的存储具有等势作用，部分的信息丢失仍可以信息得到恢复，因而网络具有容错性和联想记忆功能。


## 神经元模型
M-P神经元模型是最早的神经元模型之一：
<img src="picture\神经元模型.png" width = 90% height = 50% />
在上图中有如下特点：

- 输入：接收到来自n 个其他神经元传递过来的输入信号，输入信号通过带权重的连接进行传递。
- 处理：神经元接收到的总输入值将与神经元的阈值进行比较。
- 输出：通过“激活函数”(activation function) 处理以产生神经元的输出f
- 激活函数：对输入、输出进行函数转换，从而达到输入对输出的激活

理想的激活函数应该是阶跃函数，输入值为0时对应抑制，输入为1时对应兴奋，但是不能用因为他不连续呀。故在M-P神经元模型中，也采用Sigmoid函数来近似， Sigmoid函数将较大范围内变化的输入值挤压到 (0,1) 输出值范围内，所以也称为挤压函数（squashing function）。
<img src="picture\激活函数.png" width = 80% height = 50% />

将多个神经元按照一定层次连接起来就构成了人工神经网络。这是一个包含很多个参数的模型，整个神经网络由这些神经元相互嵌套而成，最后就会形成很复杂的分类器。

##  感知机与多层网络

前面说了神经元模型有输入处理和输出。感知机比较特殊，乍一看好像只有输入和输出，是一种十分简单的神经网络，可以实现与或非，也叫阈值逻辑单元。特点如下：

<img src="picture\感知机.png" width = 60% height = 30% />


- 感知机由两层神经元组成
- 输入层接受外界信号传递给输出
- 输出是M-P神经元



一般情况，给定数据集之后，我们需要得到权重$w_i(i=0,1,2...,n)$以及阈值$\theta$.可将$\theta$看作一个固定输入为-1的哑节点对应权重$w_{n+1}$.权重和阈值就统一为权重的学习了。

学习过程如下，对训练样例$(x,y)$，若当前的输出值为$\hat{y}$.则感知机权重$w_i$这样调整：
$$ w_i \leftarrow w_i+\Delta _i$$

$$\Delta w_i = \eta (y-\hat{y}) x_i$$

其中$\eta$为学习率，通常取一个较小的正数，
- 若预测正确，不发生变化
- 预测错误，根据错误值对$w_i$进行调整。


感知机只有输出层神经元进行激活函数处理，只有一层功能神经元。像与或非这种线性可分的感知机一定会收敛，从而求得适当的权向量$w= (w_1;w_2;...;w_{n+1})$.否则会发生震荡，例如异或这样的问题，解决非线性可分问题，考虑多层功能神经元。输出层和输入层之间成为隐含层，隐含层和输出层都含有激活函数。

多层神经网络的拓扑结构如下图所示：
<img src="picture\多层网络.png" width = 90% height = 50%>

在神经网络中，输入层与输出层之间的层称为隐含层或隐层（hidden layer），隐层和输出层的神经元都是具有激活函数的功能神经元。只需包含一个隐层便可以称为多层神经网络，常用的神经网络称为“多层前馈神经网络”（multi-layer feedforward neural network），该结构满足以下几个特点：

- 每层神经元与下一层神经元之间完全互连
- 神经元之间不存在同层连接
- 神经元之间不存在跨层连接


多层前馈神经网络 ：常见的神经网络是下图所示的层级结构，层每层神经元与下层神经元全互连，神经元之间不存在同层连接，也不存在跨连接。这样的神经网络结构通常称为多层前馈神经网络(multi-layer feedforward neural networks)。
<img src="picture\多层前馈神经网络.png" width = 100% height = 60% />

神经网络学习过程: 根据训练数据来调整神经元之间的” 连接权” 以及每个功能神经元的阈值, 即不断更新每一层的权值矩阵$w(w_0$ 包含阈值信息)

## 误差逆传播算法

多层神经网络很难训练，需要强大的学习算法，误差逆传播算法(BP)是一种很好的训练算法。一般我们说BP算法是用来搞多层前馈神经网络，当然它也可以用在其他地方。

下面是一个神经网络图:
<img src="picture\BP算法.png" width = 90% height = 50% />

上图为一个单隐层前馈神经网络的拓扑结构，BP神经网络算法也使用梯度下降法（gradient descent），以单个样本的均方误差的负梯度方向对权重进行调节。可以看出：BP算法首先将误差反向传播给隐层神经元，调节隐层到输出层的连接权重与输出层神经元的阈值；接着根据隐含层神经元的均方误差，来调节输入层到隐含层的连接权值与隐含层神经元的阈值。BP算法基本的推导过程与感知机的推导过程原理是相同的，下面给出调整隐含层到输出层的权重调整规则的推导过程：

训练样例$(x_k,y_k)$，神经网络的输出为$\hat{y_k} = (\hat{y_1^k},\hat{y_2^k},...,\hat{y_t^k})$.

具体过程感觉蛮复杂的，敲公式费劲，得到结果：
$$ \Delta \theta_j = -\eta g_i$$

$$\Delta v_{ih} = \eta e_h x_i$$

$$\Delta \gamma _h = -\eta e_h
$$

其中：
$$ e_h = b_h(1-b_h) \sum _{j=1}^l w_{hj}g_j$$

$$ g_j = \hat{y_j^k} (1-\hat{y_j^k} )(y_j^k-\hat{y_j^k} )$$
学习率η∈（0，1）控制着沿反梯度方向下降的步长，若步长太大则下降太快容易产生震荡，若步长太小则收敛速度太慢，一般地常把η设置为0.1，有时更新权重时会将输出层与隐含层设置为不同的学习率。BP算法的基本流程如下所示：
<img src="picture\BP算法流程.png" width = 100% height = 50% />

新规则是基于每个样本的预测值与真实类标的均方误差来进行权值调节，即BP算法每次更新只针对于单个样例。需要注意的是：BP算法的最终目标是要最小化整个训练集D上的累积误差，即：
$$ E = \frac{1}{m} \sum _{k=1} ^m E_k$$

如果基于累积误差最小化的更新规则，则得到了累积误差逆传播算法（accumulated error backpropagation），即每次读取全部的数据集一遍，进行一轮学习，从而基于当前的累积误差进行权值调整，因此参数更新的频率相比标准BP算法低了很多，但在很多任务中，尤其是在数据量很大的时候，往往标准BP算法会获得较好的结果。另外对于如何设置隐层神经元个数的问题，至今仍然没有好的解决方案，常使用“试错法”进行调整。

前面提到，BP神经网络强大的学习能力常常容易造成过拟合问题，有以下两种策略来缓解BP网络的过拟合问题：

- 早停：将数据分为训练集与测试集，训练集用于学习，测试集用于评估性能，若在训练过程中，训练集的累积误差降低，而测试集的累积误差升高，则停止训练。
- 引入正则化（regularization）：基本思想是在累积误差函数中增加一个用于描述网络复杂度的部分，例如所有权值与阈值的平方和，其中λ∈（0,1）用于对累积经验误差与网络复杂度这两项进行折中，常通过交叉验证法来估计。

$$ E = \lambda \frac{1}{m} \sum_{k=1}^m E_k +(1-\lambda) \sum _i w_i^2$$

## 全局最小和局部最小
模型学习的过程实质上就是一个寻找最优参数的过程，例如BP算法试图通过最快速下降来寻找使得累积经验误差最小的权值与阈值，在谈到最优时，一般会提到局部极小（local minimum）和全局最小（global minimum）。

- 局部极小解：参数空间中的某个点，其邻域点的误差函数值均不小于该点的误差函数值。
- 全局最小解：参数空间中的某个点，所有其他点的误差函数值均不小于该点的误差函数值。
<img src="picture\局部全局最小.png" width = 100% height = 50% />

要成为局部极小点，只要满足该点在参数空间中的梯度为零。局部极小可以有多个，而全局最小只有一个。全局最小一定是局部极小，但局部最小却不一定是全局最小。显然在很多机器学习算法中，都试图找到目标函数的全局最小。梯度下降法的主要思想就是沿着负梯度方向去搜索最优解，负梯度方向是函数值下降最快的方向，若迭代到某处的梯度为0，则表示达到一个局部最小，参数更新停止。因此在现实任务中，通常使用以下策略尽可能地去接近全局最小。

- 以多组不同参数值初始化多个神经网络，按标准方法训练，迭代停止后，取其中误差最小的解作为最终参数。
- 使用“模拟退火”技术，模拟退火在每一步都按照一定概率接受比当前解更差的结果，从而有助于跳出局部极小，在每次迭代过程中，接受次优解的概率要随着时间的推移二逐渐降低。
- 使用随机梯度下降，即在计算梯度时加入了随机因素，使得在局部最小时，计算的梯度仍可能不为0，从而迭代可以继续进行。

遗传算法也可用于训练神经网络以逼近全局最小，需要注意的是跳出局部最小的技术大多都是启发式，理论上没有保障。



## 其他常见神经网络
神经网络算法模型繁多，下面对几种常见的网络稍作简介。这部分内容个人感觉作为了解相关实现方法可能在后面会进行详细学习.

### RBF网络
RBF(径向基函数)网络是一种单隐层前馈神经网络，使用径向基函数作为隐层神经元激活函数，输出层是对隐层神经元输出的线性组合。

输入$d$维向量$x$,输出为实值，RBF网络表示为：
$$ \varphi(x) = \sum _{i=1} ^q w_i \rho(x,c_i)$$

其中q为隐层神经元个数，$c_i和w_i$为第$i$个隐层神经元所对应的中心和权重，$\rho$为径向基函数，通常定义为样本$x$到数据中心$c_i$之间的欧氏距离的单调函数。高斯径向基函数如下：
$$ \rho(x,c_i) = e^{-\beta_i ||x-c_i||^2}$$

训练RBF网络分为两步：1. 确定神经元中心$c_i$,常用方法包括随机取样、聚类。2. 利用BP算法确定参数$w_i和\beta_i$
### ART网络
竞争性学习是一种常用的无监督学习策略，使用该策略时，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元被抑制，也叫“胜者通吃”策略。
ART网络是竞争性学习的代表，由比较层、识别层、识别阈值、识别层每个神经元对应一个模式类，神经元数目可在训练过程中动态增长以增加新的识别类。竞争性学习的关键是产生获胜神经元，最简单方式计算输入向量与每个识别层神经元对应的模式类代表向量之间的距离，距离最小者获胜。

西瓜书上其具体竞争获胜的流程和算法如下：
<img src="picture\ART网络.png" width = 90% height = 50% />

### SOM网络
SOM网络是一种竞争学习性无监督神经网络，将高维输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层的临近神经元。

SOM训练过程很简单：接受训练样本后输出神经元计算该样本和自身携带的权向量之间的距离，距离最近的神经元成为竞争获胜者，称为最佳匹配单元。然后最佳匹配单元极其临近神经元的权向量被调整，使得权向量和当前输入样本距离缩小，不断迭代直至收敛。
<img src="picture\SOM网络.png" width = 80% height = 50% />

### 级联相关网络
一般神经网络是假定网络结构是事先固定的，训练目的是利用训练样本确定合适的链接权、阈值等。级联相关网络属于结构自适应网络的代表，能在训练过程中找到最符合数据特点的网络结构。
<img src="picture\级联相关网络.png" width = 90% height = 50% />

### Elman网络

与前馈神经网络不同，递归神经网络允许网络中出现环形结构。可以让一些神经元输出反馈回来作为输入信号，使得网络在t时刻的输出状态不仅与t时刻输入有关还和t-1时刻网络状态有关，可以处理动态变化。

Elman网络是递归神经网络，下面是西瓜书上的介绍：
<img src="picture\Elman网络.png" width = 90% height = 50% />


### Boltzman机
神经网络中有一类模型是为网络状态定义一种“能量”，能量最小化时网络达到理想状态，网络训练就是最小化这个能量函数。Boltzman机是一种基于能量的模型，神经元分为两层：显层和隐层，显层用于表示数据的输入和输出，隐层是指数据得内在表达，该模型的神经元都是布尔型的。1表示激活，0表示抑制。$s \in {(0,1)}^n$表示n个神经元的状态，$w_{ij}$表示神经元$i和j$之间的连接权，$\theta _i$表示神经元$i$的阈值，状态向量$s$对应的能量：
$$ E(s)= - \sum_{i=1}^{n-1}\sum _{j=i+1}^n w_{ij}s_is_j-\sum_{i=1}^n\theta_i s_i$$
<img src="picture\Boltzman机1.png" width = 90% height = 50% />
<img src="picture\Boltzman机2.png" width = 90% height = 50% />


## 深度学习


理论上，参数越多，模型复杂度就越高，容量（capability）就越大，从而能完成更复杂的学习任务。深度学习（deep learning）正是一种极其复杂而强大的模型。

增大模型复杂度的两个办法：一是增加隐层的数目，二是增加隐层神经元的数目。一般采用前者，不仅增加了功能神经元的数量，还增加了激活函数嵌套的层数。但是对于多隐层神经网络，经典算法如标准BP算法往往会在误差逆传播时发散（diverge），无法收敛达到稳定状态。

训练对隐层神经网络：
1.  无监督逐层训练（unsupervised layer-wise training）：每次训练一层隐节点，把上一层隐节点的输出当作输入来训练，本层隐结点训练好后，输出再作为下一层的输入来训练，这称为预训练（pre-training）。全部预训练完成后，再对整个网络进行微调（fine-tuning）训练。一个典型例子就是深度信念网络（deep belief network，简称DBN）。这种做法其实可以视为把大量的参数进行分组，先找出每组较好的设置，再基于这些局部最优的结果来训练全局最优。
2.  权共享（weight sharing）：令同一层神经元使用完全相同的连接权，典型的例子是卷积神经网络（Convolutional Neural Network，简称CNN）。这样做可以大大减少需要训练的参数数目。
<img src="picture\手写体识别.png" width = 100% height = 50% />

深度学习可以理解为一种特征学习（feature learning）或者表示学习（representation learning），无论是DBN还是CNN，都是通过多个隐层来把与输出目标联系不大的初始输入转化为与输出目标更加密切的表示，使原来只通过单层映射难以完成的任务变为可能。即通过多层处理，逐渐将初始的“低层”特征表示转化为“高层”特征表示，从而使得最后可以用简单的模型来完成复杂的学习任务。

传统任务中，样本的特征需要人类专家来设计，这称为特征工程（feature engineering）。特征好坏对泛化性能有至关重要的影响。而深度学习为全自动数据分析带来了可能，可以自动产生更好的特征。



这里关于深度学习的概念基本都是copy网上的或者西瓜书上的，深度学习是一门专门的科学了，我有一个pdf是专门将这个的，课本这一部分内容也比较简略，因此可以不求甚解等这个弄完之后再去看看吴恩达深度学习。注意深度置信网络和卷积神经网络。


## 补充：增量学习和在线学习
- 增量学习
    增量学习是指在学得模型后，在接收到训练样例时，仅根据新样例对模型进行更新，不必重复训练整个模型，并且先前学的东西不会被冲掉。
- 在线学习
  每次获得一个新样本就进行一次模型更新，在线学习是增量学习的特例，增量学习可视为批模式的在线学习。