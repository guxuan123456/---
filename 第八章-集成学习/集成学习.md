# 集成学习
所谓集成学习，就是将许多个学习器结合在一块，得到最后的输出，这样结果会综合所有学习器的性能。有时也叫多分类器系统、基于委员会的学习(committee-based learning)等。

## 个体与集成

- 集成学习
  通过构建多个学习器来完成学习任务，常可以获得比单一学习器显著优越的泛化性能，也叫多分类器系统。

- 集成学习一般结构
  先产生一组“个体学习器”，再利用某种策略将他们结合起来。个体学习器就是一般是我们前面介绍的算法。若个体学习器都属于同一类别，例如都是决策树或都是神经网络，则称该集成为同质的。若个体学习器包含多种类型的学习算法，例如既有决策树又有神经网络，则称该集成为异质的.
  <img src="picture\集成学习.png" width = 80% height = 50% />

从上面我们便可以看出，集成学习需要研究的问题：
- 个体学习器如何生成(采用什么样的)
- 个体学习器之间应该如何组织起来。

集成学习的两个重要概念：**准确性**和**多样性**。

准确性指的是个体学习器不能太差，要有一定的准确度；多样性则是个体学习器之间的输出要具有差异性。通过下面的这三个例子可以很容易看出这一点，准确度较高，差异度也较高，可以较好地提升集成性能。

<img src="picture\准确性多样性.png" width =100% height = 40%>

下面来看看集成学习是不是会比个体学习好：

考虑二分类的简单情形，假设基分类器之间相互独立（能提供较高的差异度），且错误率相等为 ε，则可以将集成器的预测看做一个伯努利实验，易知当所有基分类器中不足一半预测正确的情况下，集成器预测错误，所以集成器的错误率可以计算为
<img src="picture\集成学习错误率.png" width =70% height = 50%>

此时，集成器错误率随着基分类器的个数的增加呈指数下降，但前提是基分类器之间相互独立，在实际情形中显然是不可能的，假设训练有A和B两个分类器，对于某个测试样本，显然满足：P（A=1 | B=1）> P（A=1），因为A和B为了解决相同的问题而训练，因此在预测新样本时存在着很大的联系。因此，**个体学习器的“准确性”和“差异性”本身就是一对矛盾的变量**，准确性高意味着牺牲多样性，所以产生“**好而不同**”的个体学习器正是集成学习研究的核心。

**两大类集成学习方法**
  1. 个体学习器之间存在强依赖关系，必须串行生成的序列化方法(Boosting)
  2. 个体学习器之间不存在强依赖关系，可同时生成并行化方法(Bagging和随机森林)

## Boosting算法
该算法可将弱学习器(泛化性能略优于随机猜测的学习器)提升为强学习器的一族算法,该算法主要关注降低偏差，该算法主要思想是先根据样本整出一个学习器，在根据上面的学习器将样本进行调整，然后在训练一个，最后根据不同权重把学习器叠加得到最后的训练结果。具体工作机制如下：
1. 从初始训练集训练出一个基学习器$h_t$，评估$h_t$ 性能，并计算$h_t$ 的权重$α_t$；
2. 基于$h_t$ 对训练样本分布进行调整，即区别对待在$h_t$ 中做对和做错的训练样本
3. 基于调整后的样本分布来训练下一个基学习器$h_{t+1}$
4. 重复进行，直至基学习器数目达到事先指定的值$T$
5. 最终将这$T $个基学习器进行加权结合：   $ H(x) = sign(\sum ^T_{t=1} \alpha _t h_t(x)) $

Boosting族算法最著名、使用最为广泛的就是AdaBoost，因此下面主要是对AdaBoost算法进行介绍。AdaBoost使用的是**指数损失函数**，因此AdaBoost的权值与样本分布的更新都是围绕着最小化指数损失函数进行的。看到这里回想一下之前的机器学习算法，**不难发现机器学习的大部分带参模型只是改变了最优化目标中的损失函数**：如果是Square loss，那就是最小二乘了；如果是Hinge Loss，那就是著名的SVM了；如果是log-Loss，那就是Logistic Regression了。下面是AdaBoost算法流程：
<img src="picture\adaboost算法.png" width =100% height = 50%>

第一个基分类器$h_1$ 是通过直接将基学习算法用于初始数据分布而得；此后迭代地生成$h_t$ 和$α_t$,当基分类器$h_t$ 基于分布$D_t$ 产生后，该基分类器的权重$α_t$应使得$α_th_t$ 最小化指数损失函数。也就是说我们主要考虑的是怎么算$h_t$和$\alpha_t$.然后这个计算感觉还是挺复杂的，但是最后的结果不复杂，推导过程比较复杂，感兴趣可以看看(具体参见本文件西瓜书174-176页。但是在使用时只需要知道上面式子的更新表达式就可以了。

**AdaBoost的核心步骤就是计算基学习器权重和样本权重分布**，更新的公式就是前面流程里面的公式，具体可按照前面说的参见西瓜书。Boosting算法要求基学习器能对特定分布的数据进行学习，即每次都更新样本分布权重，这里书上提到了两种方法：“重赋权法”（re-weighting）和“重采样法”（re-sampling）：
- **重赋权法** : 
  对每个样本附加一个权重，这时涉及到样本属性与标签的计算，都需要乘上一个权值。
-  **重采样法** : 
  对于一些无法接受带权样本的及学习算法，适合用“重采样法”进行处理。方法大致过程是，根据各个样本的权重，对训练数据进行重采样，初始时样本权重一样，每个样本被采样到的概率一致，每次从N个原始的训练样本中按照权重有放回采样N个样本作为训练集，然后计算训练集错误率，然后调整权重，重复采样，集成多个基学习器。

##  Bagging与Random Forest(随机森林)
相比之下，Bagging与随机森林算法就简洁了许多，上面已经提到产生“好而不同”的个体学习器是集成学习研究的核心，即在保证基学习器准确性的同时增加基学习器之间的多样性。而这两种算法的基本思想都是通过“自助采样”的方法来增加多样性。实现不同学习器之间尽可能相互独立，使基学习器尽可能产生较大差异。

该算法主要涉及的是如何将训练集分成许多个相互有交叠的采样子集的问题。
### bagging算法
Bagging是一种并行式的集成学习方法，即基学习器的训练之间没有前后顺序可以同时进行，Bagging使用“有放回”采样的方式选取训练集，对于包含m个样本的训练集，进行m次有放回的随机采样操作，从而得到m个样本的采样集，这样训练集中有接近36.8%的样本没有被采到。按照相同的方式重复进行，我们就可以采集到T个包含m个样本的数据集，从而训练出T个基学习器，最终对这T个基学习器的输出进行结合。

也就说该算法主要是训练集样本的分类问题，其直接基于自助采样法。

#### 自助采样法
前面自主采样法大致可能记得一点，现在重新整理一下：
<img src="picture\自助采样法.png" width =80% height = 50%>


下面给出该算法的算法流程：
<img src="picture\bagging算法流程.png" width =100% height = 50%>

可以看出Bagging主要通过**样本的扰动**来增加基学习器之间的多样性，因此Bagging的基学习器应为那些对训练集十分敏感的不稳定学习算法，例如：神经网络与决策树等。从偏差-方差分解来看，Bagging算法主要关注于降低方差，即通过多次重复训练提高稳定性。不同于AdaBoost的是，Bagging可以十分简单地移植到多分类、回归等问题。总的说起来则是：**AdaBoost关注于降低偏差，而Bagging关注于降低方差。**

该算法的复杂度和使用一个基算法的复杂度同阶。对于预测输出结果，对于分类任务，常采用投票法；对于回归任务常采用平均法，当分类预测出现同样票数时，就随机选择一个。

### 随机森林
随机森林的概念也很好理解。随机森林(Random Forest)是Bagging的一个拓展体，它的基学习器固定为决策树，多棵树也就组成了森林，而“随机”则在于选择划分属性的随机，随机森林在训练基学习器时，也采用有放回采样的方式添加样本扰动，同时它还引入了一种**属性扰动**，即在基决策树的训练过程中，在选择划分属性时，RF先从候选属性集中随机挑选出一个包含$K$个属性的子集，再从这个子集中选择最优划分属性，一般推荐$K=log_2(d)$。

这样随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动，从而进一步提升了基学习器之间的差异度。相比决策树的Bagging集成，随机森林的起始性能较差(由于属性扰动，基决策树的准确度有所下降)，但随着基学习器数目的增多，随机森林往往会收敛到更低的泛化误差。同时不同于Bagging中决策树从所有属性集中选择最优划分属性，随机森林只在属性集的一个子集中选择划分属性，因此训练效率更高。
<img src="picture\随机森林.png" width =80% height = 50%>

## 结合策略
前面说了采用什么样的基学习器，现在来说说不同基学习器的结合策略。结合策略指的是在训练好基学习器后，如何将这些基学习器的输出结合起来产生集成模型的最终输出，下面将介绍一些常用的结合策略：

### 平均法--回归问题
平均法有简单平均和加权平均两种。
<img src="picture\简单平均法.png" width =70% height = 50%>
<img src="picture\加权平均法.png" width =70% height = 50%>

简单平均法是加权平均法的一种特例，加权平均法可以认为是集成学习研究的基本出发点。由于各个基学习器的权值在训练中得出，**一般而言，在个体学习器性能相差较大时宜使用加权平均法，在个体学习器性能相差较小时宜使用简单平均法**。


### 投票法--分类问题
投票法也有三种投票方式
#### 绝对多数投票法
即若某标记得票过半数，则预测为该标记；否则拒绝预测。
<img src="picture\绝对多数投票法.png" width =70% height = 50%>

#### 相对多数投票法
即预测为得票最多的标记，若同时有多个标记获最高票，则从中随机选取一个。
<img src="picture\相对多数投票法.png" width =70% height = 50%>

#### 加权投票法
在相对多数投票法基础上加一个权重
<img src="picture\加权投票法.png" width =70% height = 50%>

绝对多数投票法（majority voting）提供了拒绝选项，这在可靠性要求很高的学习任务中是一个很好的机制。若学习任务要求必须提供预测结果，则绝对多数投票法将退化
为相对多数投票法。

对于分类任务，各个基学习器的输出值有两种类型，分别为类标记和类概率，两种不同的类型不能混合使用。
<img src="picture\投票法.png" width =80% height = 50%>

一些在产生类别标记的同时也生成置信度的学习器，置信度可转化为类概率使用，**一般基于类概率进行结合往往比基于类标记进行结合的效果更好**，需要注意的是对于异质集成，其类概率不能直接进行比较，此时需要将类概率转化为类标记输出，然后再投票。

### 学习法
当训练数据很多时，一种更为强大的结合策略是使用“学习法”，即通过另一个学习器来进行结合。

Stacking 是学习法的典型代表。这里我们把个体学习器称为初级学习器，用于结合的学习器称为次级学习器或元学习器(meta-learner)。

Stacking 先从初始数据集训练出初级学习器，然后“生成”一个新数据集用于训练次级学习器。在这个新数据集中，初级学习器的输出被当作样例输入特征，而初始样本的标记仍被当作样例标记.
<img src="picture\stacking算法.png" width =100% height = 50%>

关于该算法的一些讨论，主要还是次级训练集的训练样本如何选择。
<img src="picture\算法讨论.png" width =80% height = 50%>


## 多样性
泛化能力强的集成由好而不同的个体学习器构建：即个体学习器的准确性越高、多样性越大，则集成的泛化能力越强。这一部分就主要注重于个体学习器的多样性问题，先讨论误差-分歧分解、在搞一哈如何度量多样性，最后是多样性如何增强。

### 误差-分歧分解
这一部分就是从数学的角度说明个体学习器和集成之间的关系，即：个体学习器准确型越高、多样性越大，则集成越好。
<img src="picture\误差分歧分解.png" width =80% height = 50%>

### 多样性度量
用于度量集成中个体分类器的多样性，即估算个体学习器的多样化程度，典型做法是考虑个体分类器的两两相似/不相似性。
<img src="picture\多样性度量1.png" width =80% height = 50%>

下面是几个常见的多样性度量(知道有这个东西就行了，感觉用不上啊)
<img src="picture\多样性度量2.png" width =80% height = 50%>

### 多样性增强
多样性增强才是我们需要掌握的，掌握之后就会增强多样性了。一般思路是在学习过程中引入随机性，常见做法主要是对数据样本、输入属性、输出表示、算法参数进行扰动。

 **数据样本扰动**，即利用具有差异的数据集来训练不同的基学习器。例如：有放回自助采样法，但此类做法只对那些不稳定学习算法十分有效，例如：决策树和神经网络等，训练集的稍微改变能导致学习器的显著变动。
 **输入属性扰动**，即随机选取原空间的一个子空间来训练基学习器。例如：随机森林，从初始属性集中抽取子集，再基于每个子集来训练基学习器。但若训练集只包含少量属性，则不宜使用属性扰动。
 **输出表示扰动**，此类做法可对训练样本的类标稍作变动，或对基学习器的输出进行转化。
 **算法参数扰动**，通过随机设置不同的参数，例如：神经网络中，随机初始化权重与随机设置隐含层节点数。













